{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPE 256 Programming Assignment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Id : 013774228 , Sarath Chandra Makkena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supporting libraries used : Surprise, Pandas, Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step :Import libraries and load respective dataset into pandas dataframe \n",
    "# Then used surprise library fucntion load_from_df() to load from pandas dataframe\n",
    "# After which building full trainset using entire dataset\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import Dataset, evaluate\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import KNNBasic\n",
    "\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n",
    "\n",
    "df = pd.read_csv('train_newdat.csv')\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'book_id', 'rating']], reader)\n",
    "trainingSet = data.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x11f708898>\n"
     ]
    }
   ],
   "source": [
    "#Print the surprise dataset\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the given data set ratings are scrambled, so trying to sort in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12726</td>\n",
       "      <td>7784</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359885</th>\n",
       "      <td>30537</td>\n",
       "      <td>759611</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151869</th>\n",
       "      <td>33101</td>\n",
       "      <td>375901</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151871</th>\n",
       "      <td>13492</td>\n",
       "      <td>197084</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648308</th>\n",
       "      <td>490</td>\n",
       "      <td>37190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  book_id  rating\n",
       "0         12726     7784       5\n",
       "359885    30537   759611       5\n",
       "151869    33101   375901       5\n",
       "151871    13492   197084       5\n",
       "648308      490    37190       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting values in descending order and displaying first few rows using head()\n",
    "df.sort_values(['rating'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second step : loading test into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset is loaded using pandas read_csv\n",
    "dt = pd.read_csv('test_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it's important to have basic overview of tarining set we have, Based on which we can plan for pre-processing data. Now describing the given data frame to know whether any null values or NAN values present in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>700000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18895.764374</td>\n",
       "      <td>4.970340e+06</td>\n",
       "      <td>2.644934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10745.949583</td>\n",
       "      <td>8.443227e+06</td>\n",
       "      <td>2.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9558.000000</td>\n",
       "      <td>7.453200e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18986.000000</td>\n",
       "      <td>4.349280e+05</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27946.000000</td>\n",
       "      <td>6.578293e+06</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37230.000000</td>\n",
       "      <td>3.645941e+07</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id       book_id         rating\n",
       "count  700000.000000  7.000000e+05  700000.000000\n",
       "mean    18895.764374  4.970340e+06       2.644934\n",
       "std     10745.949583  8.443227e+06       2.051200\n",
       "min         0.000000  5.000000e+00       0.000000\n",
       "25%      9558.000000  7.453200e+04       0.000000\n",
       "50%     18986.000000  4.349280e+05       3.000000\n",
       "75%     27946.000000  6.578293e+06       4.000000\n",
       "max     37230.000000  3.645941e+07       5.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20989</td>\n",
       "      <td>1832332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37040</td>\n",
       "      <td>191139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36167</td>\n",
       "      <td>28449164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9398</td>\n",
       "      <td>24693869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29848</td>\n",
       "      <td>8127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   book_id\n",
       "0    20989   1832332\n",
       "1    37040    191139\n",
       "2    36167  28449164\n",
       "3     9398  24693869\n",
       "4    29848      8127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking whether test set loaded into data frame dt.\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = pd.read_csv('train_newdat.csv')\n",
    "target = 'Disbursed'\n",
    "IDcol = 'ID'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(gsearch3.best_estimator_, train, predictors)\n",
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here am trying to use GridSeachCV evaluating method availble in surprise library to figure out optimal parameter for given data set. Which takes type of prediction algorithm i.e. alogorithm class, parameter grid, error measure type, and data set split proportion. As am going to use SVD (Singular Value Decomposition) predication measuring algorithm, which's having many tuning params, so parameters range for  lr_all (learning rate), reg_all (regularisation),n_factors into GridsearchCV. it works like bruteforce technique, check as possible combinations with-in the range and returns optimal parameters givin better RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_all': 0.1, 'reg_all': 0.5, 'n_factors': 400}\n"
     ]
    }
   ],
   "source": [
    "# listing out parameters into param_grid, inorder to pass it as arguements for GridSearchCV parameters\n",
    "# along with type of predction algorithm , parameters are fed for gridsearch to find optimal tuning parameters for given dataset.\n",
    "# resultant is to print the best fit parameters \n",
    "param_grid = {'lr_all' : [.001, .1], 'reg_all' : [.001, .5], 'n_factors' : [150, 400]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv = 5)\n",
    "gs.fit(data)\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As optimal parameters available for SVD, Time to pulgin those parameters and run the algorithm to train our model. Once training is finished accuracy is measured using evaluation method RMSE. lower the rmse value better the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4405\n",
      "RMSE: 1.4412\n",
      "RMSE: 1.4388\n",
      "RMSE: 1.4367\n",
      "RMSE: 1.4370\n"
     ]
    }
   ],
   "source": [
    "#SVD() is used as algorithm  with learning rate=0.1, regulation rate=0.5 and factors to be 400\n",
    "# print RMSE for each stage as am splitting dataset into 5 parts using KFold.\n",
    "\n",
    "algo1=SVD(n_epochs=50,lr_all=0.1,reg_all =0.5,n_factors =400)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo1.fit(trainingSet)\n",
    "    predictions = algo1.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For final submission into Kaggle criteria for uploading result, criteria is to concatenate two columns (user_id,book_id) into one coulmn, Here am using numpy to append values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list result to store predicted values \n",
    "# ID list contains the concatenated ID-User and book values\n",
    "import numpy as np\n",
    "result=[]\n",
    "result1=[]\n",
    "id=[]\n",
    "for index, row in dt.iterrows():\n",
    "    id.append(str((row['user_id']))+'-'+str((row['book_id'])))\n",
    "    result1.append(algo1.predict(row['user_id'], row['book_id']).est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe to store the ID and Predicted ratings\n",
    "result=pd.DataFrame({'user_id-book_id':pd.Series(id),'rating':pd.Series(result1) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id-book_id    rating\n",
      "0        20989-1832332  0.396672\n",
      "1         37040-191139  2.588991\n",
      "2       36167-28449164  1.301240\n",
      "3        9398-24693869  0.908403\n",
      "4           29848-8127  2.464246\n",
      "5          14822-38674  4.201941\n",
      "6        11384-1487686  3.807458\n",
      "7       15022-11630978  1.800384\n",
      "8           5692-19543  2.772055\n",
      "9           3522-34268  2.109552\n",
      "10        19940-824204  4.360288\n",
      "11        13048-233818  1.368019\n",
      "12          6334-17496  1.265943\n",
      "13        12090-955942  1.184463\n",
      "14        18985-902750  1.512923\n",
      "15         32410-20694  3.472420\n",
      "16        9476-1812559  3.733182\n",
      "17       29226-4634866  1.869722\n",
      "18        13106-105549  4.316514\n",
      "19      14303-32078585  0.169351\n",
      "20          20799-8127  3.617313\n",
      "21        35002-850253  2.643288\n",
      "22          3150-28195  2.724413\n",
      "23        6640-9762941  2.815556\n",
      "24        36273-511689  2.926007\n",
      "25      23290-30201521  4.320704\n",
      "26        17518-290499  2.187012\n",
      "27       20755-8521055  1.164048\n",
      "28       35014-4812114  2.508664\n",
      "29        19292-152384  0.031753\n",
      "...                ...       ...\n",
      "299576  21070-27209447  3.798557\n",
      "299577      5635-22917  2.581621\n",
      "299578  37210-12909265  3.419136\n",
      "299579   25379-7801625  3.671756\n",
      "299580    28102-275247  2.802869\n",
      "299581     13964-91244  2.872726\n",
      "299582    37145-815263  3.429686\n",
      "299583      2393-83369  1.671273\n",
      "299584    30392-310258  3.388622\n",
      "299585      4653-84981  2.884466\n",
      "299586    28591-793903  0.037143\n",
      "299587    16914-967662  2.872273\n",
      "299588   23617-1069585  2.224604\n",
      "299589   17312-5986665  1.193573\n",
      "299590    23518-232576  3.367539\n",
      "299591   17041-2021122  2.704897\n",
      "299592     30736-37732  2.305793\n",
      "299593  31279-13152107  3.003048\n",
      "299594  15209-11423979  1.335259\n",
      "299595     9583-607430  3.544526\n",
      "299596   1939-24452943  2.115170\n",
      "299597    13530-808853  3.260330\n",
      "299598   18913-5242130  3.240834\n",
      "299599    23378-971239  1.964051\n",
      "299600  30907-16685922  1.679797\n",
      "299601     15976-38709  2.308115\n",
      "299602     24853-11312  1.179077\n",
      "299603  29982-10697427  2.852093\n",
      "299604     6324-157993  1.456763\n",
      "299605      27262-6310  2.298974\n",
      "\n",
      "[299606 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result into CSV file\n",
    "result.to_csv('Results_Sar_rep.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References\n",
    "- https://surprise.readthedocs.io/en/stable/index.html\n",
    "- https://surprise.readthedocs.io/en/stable/prediction_algorithms.html\n",
    "- https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD \n",
    "- https://surprise.readthedocs.io/en/stable/evaluate.html?highlight=GridSearchCV#surprise.evaluate.evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
